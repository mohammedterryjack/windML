{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "  \"statement positive test this is a lovely test .\",\n",
    "  \"statement negative test this is a horrible test .\",\n",
    "  \"statement neutral test this is a test .\",\n",
    "]\n",
    "batch_of_tokens = list(map(lambda sentence:sentence.split(),examples))\n",
    "\n",
    "inputs = []\n",
    "targets = []\n",
    "for tokens in batch_of_tokens:\n",
    "  for index in range(1,len(tokens)):\n",
    "    context = ' '.join(tokens[:index])\n",
    "    inputs.append(context)\n",
    "    targets.append(tokens[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffast import load\n",
    "\n",
    "tokeniser = load('poincare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, zeros\n",
    "\n",
    "def one_hot(id, max_len):\n",
    "  vector = zeros(max_len)\n",
    "  vector[id] = 1 \n",
    "  return vector\n",
    "\n",
    "max_length = len(tokeniser)\n",
    "encode_inputs = lambda sentence: tokeniser.encode(sentence).vector\n",
    "encode_targets = lambda word: one_hot(tokeniser.encode(word).ids[0], max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array(list(map(encode_inputs,inputs)))\n",
    "T = array(list(map(encode_targets,targets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from windML import RecurrentELM\n",
    "\n",
    "model = RecurrentELM(tokeniser.size, len(tokeniser))\n",
    "model.fit(X,T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_nlg\")\n",
    "model = RecurrentELM(tokeniser.size, len(tokeniser), load_path=\"my_nlg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"statement positive test\"\n",
    "generated_ids = list(model.generate(\n",
    "    prompt_token_ids=tokeniser.encode(prompt).ids,\n",
    "    token_id_vectoriser=lambda token_ids:tokeniser.decode(token_ids).vector\n",
    "))\n",
    "str(tokeniser.decode(generated_ids))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
